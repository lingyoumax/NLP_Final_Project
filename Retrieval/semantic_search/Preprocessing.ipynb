{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('qap.csv')\n",
    "df_cleaned = df.dropna()\n",
    "print(df_cleaned['Question'].str.contains('in the study', case=False, na=False).sum())\n",
    "df_cleaned = df_cleaned[~df_cleaned['Question'].str.contains('in the study', case=False, na=False)]\n",
    "df_cleaned.to_csv('train_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_2.csv')\n",
    "print(df['Question'].str.contains('retracted', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('retracted', case=False, na=False)]\n",
    "df.to_csv('train_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_3.csv')\n",
    "print(df['Question'].str.contains('in this study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('in this study', case=False, na=False)]\n",
    "df.to_csv('train_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1179\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_4.csv')\n",
    "print(df['Question'].str.contains('the study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('the study', case=False, na=False)]\n",
    "df.to_csv('train_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_5.csv')\n",
    "print(df['Question'].str.contains('this study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('this study', case=False, na=False)]\n",
    "df.to_csv('train_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_6.csv')\n",
    "print(df['Question'].str.contains('in the current study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('in the current study', case=False, na=False)]\n",
    "df.to_csv('train_7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_7.csv')\n",
    "print(df['Question'].str.contains('in this paper', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('in this paper', case=False, na=False)]\n",
    "df.to_csv('train_8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_8.csv')\n",
    "print(df['Question'].str.contains('in their study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('in their study', case=False, na=False)]\n",
    "df.to_csv('train_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_9.csv')\n",
    "print(df['Question'].str.contains('in their pilot study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('in their pilot study', case=False, na=False)]\n",
    "df.to_csv('train_10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_10.csv')\n",
    "print(df['Question'].str.contains('authors', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('authors', case=False, na=False)]\n",
    "df.to_csv('train_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_11.csv')\n",
    "print(df['Question'].str.contains('present study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('present study', case=False, na=False)]\n",
    "df.to_csv('train_12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_12.csv')\n",
    "print(df['Question'].str.contains('Is this', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('Is this', case=False, na=False)]\n",
    "df.to_csv('train_13.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_13.csv')\n",
    "print(df['Question'].str.contains('in the paper', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('in the paper', case=False, na=False)]\n",
    "df.to_csv('train_14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_14.csv')\n",
    "print(df['Question'].str.contains('their study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('their study', case=False, na=False)]\n",
    "df.to_csv('train_15.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_15.csv')\n",
    "print(df['Question'].str.contains('author', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('author', case=False, na=False)]\n",
    "df.to_csv('train_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_16.csv')\n",
    "print(df['Question'].str.contains('case study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('case study', case=False, na=False)]\n",
    "df.to_csv('train_17.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_16.csv')\n",
    "print(df['Question'].str.contains('Study I', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('Study I', case=False, na=False)]\n",
    "df.to_csv('train_17.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_17.csv')\n",
    "print(df['Question'].str.contains('current study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('current study', case=False, na=False)]\n",
    "df.to_csv('train_18.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_18.csv')\n",
    "print(df['Question'].str.contains('in this comparative study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('in this comparative study', case=False, na=False)]\n",
    "df.to_csv('train_19.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_19.csv')\n",
    "print(df['Question'].str.contains('in the article', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('in the article', case=False, na=False)]\n",
    "df.to_csv('train_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_20.csv')\n",
    "print(df['Question'].str.contains('pilot study', case=False, na=False).sum())\n",
    "df = df[~df['Question'].str.contains('pilot study', case=False, na=False)]\n",
    "df.to_csv('train_21.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_21.csv')\n",
    "evaluation_df = df.sample(n=1000, random_state=1)\n",
    "evaluation_df.to_csv('evaluation.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qap = pd.read_csv('train_22.csv')\n",
    "splitted = pd.read_csv('splitted_pubmed_data.csv')\n",
    "\n",
    "pmid_counts = splitted['PMID'].value_counts()\n",
    "splitted_filtered = splitted[splitted['PMID'].map(pmid_counts) == 1]\n",
    "\n",
    "merged_df = qap.merge(splitted_filtered, how='left', left_on='PMID', right_on='PMID')\n",
    "result_df = merged_df[['Question', 'Answer', 'chunk_text']]\n",
    "result_df.to_csv('merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import voyageai\n",
    "import os\n",
    "\n",
    "# Initialize the Voyage.ai client with the provided API key\n",
    "vo = voyageai.Client(api_key=\"pa-VidMEe9WZqvQl1nxwnR7PmW4uDGmHia0lzVyX0ftboo\")\n",
    "\n",
    "# Set up the text splitter with a specified chunk size\n",
    "text_splitter = NLTKTextSplitter(chunk_size=500)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove newline characters and excessive spaces\n",
    "    return ' '.join(text.replace('\\n', ' ').split())\n",
    "\n",
    "input_file = 'merged.csv'\n",
    "output_file = 'updated_merged.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Check if the output file already exists to avoid overwriting data\n",
    "if os.path.exists(output_file):\n",
    "    processed_df = pd.read_csv(output_file)\n",
    "else:\n",
    "    processed_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "processed_indices = set(processed_df.index)\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\"):\n",
    "    if index in processed_indices:\n",
    "        continue\n",
    "    # Split the text into chunks\n",
    "    chunks = [clean_text(chunk) for chunk in text_splitter.split_text(row['chunk_text'])]\n",
    "\n",
    "    # Get the embedding vectors for each chunk\n",
    "    chunk_vectors = vo.embed(chunks, model=\"voyage-lite-01-instruct\", input_type=\"document\").embeddings\n",
    "\n",
    "    # Get the embedding vector for the question\n",
    "    question_vector = vo.embed(row['Question'], model=\"voyage-lite-01-instruct\", input_type=\"document\").embeddings[0]\n",
    "\n",
    "    # Calculate cosine similarity between question and each chunk\n",
    "    similarities = [cosine_similarity([question_vector], [chunk_vector])[0][0] for chunk_vector in chunk_vectors]\n",
    "\n",
    "    # Identify the top 3 most similar chunks\n",
    "    top_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:3]\n",
    "    top_chunks = [chunks[i] for i in top_indices]\n",
    "\n",
    "    # Update the DataFrame with the most relevant chunks\n",
    "    df.at[index, 'chunk_text'] = top_chunks[0] if top_chunks else None\n",
    "    df.at[index, 'Top2'] = top_chunks[1] if len(top_chunks) > 1 else None\n",
    "    df.at[index, 'Top3'] = top_chunks[2] if len(top_chunks) > 2 else None\n",
    "\n",
    "    # Append the processed row to the output file, creating a new file if it doesn't exist\n",
    "    df.iloc[[index]].to_csv(output_file, mode='a', header=not os.path.exists(output_file), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "\n",
    "df = pd.read_csv('updated_qad.csv')\n",
    "\n",
    "train_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    query = row['Question']\n",
    "    pos = [row['chunk_text']]\n",
    "    neg = random.choice(list(df[df.index != index]['chunk_text']))\n",
    "    train_data.append({\"query\": query, \"pos\": pos, \"neg\": [neg]})\n",
    "\n",
    "with open('train_data.jsonl', 'w') as outfile:\n",
    "    for entry in train_data:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('splitted_pubmed_data_NLTK.csv')\n",
    "\n",
    "with open('candidate_pool.jsonl', 'w', encoding='utf-8') as file:\n",
    "    for text in df['chunk_text']:\n",
    "        json_obj = json.dumps({\"text\": text})\n",
    "        file.write(json_obj + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python3 -m FlagEmbedding.baai_general_embedding.finetune.hn_mine \\\n",
    "--model_name_or_path BAAI/bge-large-en-v1.5  \\\n",
    "--input_file train_data.jsonl \\\n",
    "--output_file qa_finetune_data_minedHN.jsonl \\\n",
    "--range_for_sampling 50-300 \\\n",
    "--candidate_pool candidate_pool.jsonl \\\n",
    "--use_gpu_for_searching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
