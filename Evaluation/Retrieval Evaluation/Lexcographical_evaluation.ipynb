{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import yake\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from typing import List\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "kw_extractor = yake.KeywordExtractor(n=1,\n",
    "                                     dedupLim=0.9,\n",
    "                                     top=10,\n",
    "                                     features=None)\n",
    "\n",
    "\n",
    "class BM25:\n",
    "    def __init__(self, corpus: List[List[str]], k1=1.5, b=0.95):\n",
    "        self.corpus = corpus\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.documents_number = len(corpus)\n",
    "        self.avgdl = sum(len(document) for document in corpus) / self.documents_number\n",
    "        self.df = self._calculate_df()\n",
    "        self.idf = self._calculate_idf()\n",
    "\n",
    "    def _calculate_df(self):\n",
    "        df = {}\n",
    "        for document in self.corpus:\n",
    "            for word in set(document):\n",
    "                df[word] = df.get(word, 0) + 1\n",
    "        return df\n",
    "\n",
    "    def _calculate_idf(self):\n",
    "        idf = {}\n",
    "        for word, freq in self.df.items():\n",
    "            idf[word] = math.log((self.documents_number - freq + 0.5) / (freq + 0.5) + 1)\n",
    "        return idf\n",
    "\n",
    "    def _score(self, document, query):\n",
    "        score = 0.0\n",
    "        for word in query:\n",
    "            if word in self.df:\n",
    "                idf = self.idf[word]\n",
    "                term_freq = document.count(word)\n",
    "                score += (idf * term_freq * (self.k1 + 1)) / (\n",
    "                        term_freq + self.k1 * (1 - self.b + self.b * len(document) / self.avgdl))\n",
    "        return score\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        scores = []\n",
    "        for index, document in enumerate(self.corpus):\n",
    "            score = self._score(document, query)\n",
    "            scores.append((index, score))\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f5d6c42-6082-4d80-96ff-3dc229722da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_bm25(query: str, bm25, top_k):\n",
    "    global df\n",
    "    tokenized_query = query.split()\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    result = {}\n",
    "    for doc_index, score in sorted_scores:\n",
    "        pmid = df.iloc[doc_index]['PMID']\n",
    "        result[pmid] = score\n",
    "    return list(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491d5e1a-0011-470a-9260-900a0ce5d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, df, keywords, bm25, top_k):\n",
    "    tokenized_query = query.split()\n",
    "    tokenized_query.extend(keywords)\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    result = {}\n",
    "    for doc_index, score in sorted_scores:\n",
    "        pmid = df.iloc[doc_index]['PMID']\n",
    "        result[pmid] = score\n",
    "    return list(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b98d875-1ce5-45c9-89da-8055723f0840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text):\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    keywords_set = {word for word, _ in keywords}\n",
    "    return list(set(keywords_set))\n",
    "\n",
    "\n",
    "def query_pre_process(query):\n",
    "    proper_nouns = extract_keywords(query)\n",
    "    proper_nouns = [word for word in proper_nouns if word.lower() not in ENGLISH_STOP_WORDS] * 1\n",
    "    return proper_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343dc2e9-08be-46c8-9c57-f67876e184ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./PubmedDataSet.csv')\n",
    "texts = df['Abstract'].tolist()\n",
    "tokenized_texts = [doc.split() for doc in texts]\n",
    "bm25_abstract = BM25(tokenized_texts)\n",
    "\n",
    "df_test = pd.read_csv('./evaluation.csv')\n",
    "test = []\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    small_list = [row[\"Question\"], row[\"PMID\"]]\n",
    "    test.append(small_list)\n",
    "random.seed(42)\n",
    "random.shuffle(test)\n",
    "test = test[:100]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3247cd2-f8fc-4148-8e56-a944ce187b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [03:21<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1-accuracy of bm25 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for query, pmid in tqdm(test):\n",
    "    top_pmids = search_bm25(query, bm25_abstract, 1)\n",
    "    if pmid in top_pmids:\n",
    "        t += 1\n",
    "print(f'top1-accuracy of bm25 {t / len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4149de2a-8317-4f2e-b34a-25ef993a7561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [03:20<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR of bm25 is 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Q = len(test)\n",
    "MRR = 0\n",
    "for query, pmid in tqdm(test):\n",
    "    top_pmids = search_bm25(query, bm25_abstract, 1)\n",
    "    try:\n",
    "        rank = top_pmids.index(pmid) + 1\n",
    "        MRR += 1 / rank\n",
    "    except:\n",
    "        rank = 0\n",
    "MRR = MRR / Q\n",
    "print(f'MRR of bm25 is {MRR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9c6dc1-ba66-42d0-8555-6ff5fec705b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import yake\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from typing import List\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "kw_extractor = yake.KeywordExtractor(n=1,\n",
    "                                     dedupLim=0.9,\n",
    "                                     top=10,\n",
    "                                     features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "325534aa-ab41-432f-9f6c-82cef6596d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./PubmedDataSet.csv')\n",
    "texts = df['Abstract'].tolist()\n",
    "tokenized_texts = [doc.split() for doc in texts]\n",
    "bm25_abstract = BM25(tokenized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "645cd494-d3b9-4a39-8450-2229dc51b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('./splitted_pubmed_data_NLTK.csv')\n",
    "df_test = pd.read_csv('./evaluation.csv')\n",
    "test = []\n",
    "for index, row in df_test.iterrows():\n",
    "    small_list = [row[\"Question\"], row[\"PMID\"]]\n",
    "    test.append(small_list)\n",
    "random.seed(42)\n",
    "random.shuffle(test)\n",
    "test = test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2258afc-55f6-45cb-875c-cd6caec31a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [04:55<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1-accuracy of hierarchical bm25  0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for query, pmid in tqdm(test):\n",
    "    keywords = query_pre_process(query)\n",
    "    result_pmids_scores = search(query, df, keywords, bm25_abstract, top_k=30)\n",
    "    mask = df2['PMID'].isin(result_pmids_scores)\n",
    "    df_t = df2[mask]\n",
    "    texts = df_t['chunk_text'].tolist()\n",
    "    tokenized_texts = [doc.split() for doc in texts]\n",
    "\n",
    "    bm25_chunk = BM25(tokenized_texts)\n",
    "    result_pmids_scores = search(query, df_t, keywords, bm25_chunk, top_k=1)\n",
    "    if pmid in result_pmids_scores:\n",
    "        t += 1\n",
    "print(f'top1-accuracy of hierarchical bm25  {t / len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e18b314-9bce-44e6-b6cb-bc91b602af6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [04:59<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR of hierarchical bm25 is 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Q = len(test)\n",
    "MRR = 0\n",
    "for query, pmid in tqdm(test):\n",
    "    keywords = query_pre_process(query)\n",
    "    result_pmids_scores = search(query, df, keywords, bm25_abstract, top_k=30)\n",
    "    mask = df2['PMID'].isin(result_pmids_scores)\n",
    "    df_t = df2[mask]\n",
    "    texts = df_t['chunk_text'].tolist()\n",
    "    tokenized_texts = [doc.split() for doc in texts] \n",
    "\n",
    "    bm25_chunk = BM25(tokenized_texts)\n",
    "    result_pmids_scores = search(query, df_t, keywords, bm25_chunk, top_k=1)\n",
    "\n",
    "    try:\n",
    "        rank = result_pmids_scores.index(pmid) + 1\n",
    "        MRR += 1 / rank\n",
    "    except:\n",
    "        rank = 0\n",
    "MRR = MRR / Q\n",
    "print(f'MRR of hierarchical bm25 is {MRR}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
