{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "df_single_train=pd.read_csv(\"single_type_train.csv\")\n",
    "df_single_test=pd.read_csv(\"single_type_test.csv\")\n",
    "df_multi_train=pd.read_csv(\"multi_type_train.csv\")\n",
    "df_multi_test=pd.read_csv(\"multi_type_test.csv\")\n",
    "\n",
    "train_method=\"all_data\"\n",
    "load_model=True\n",
    "load_model_name=\"model\\model_state_dict_all_data_1.pth\"\n",
    "\n",
    "if os.path.exists('runs/{:}/loss'.format(train_method)):\n",
    "    shutil.rmtree('runs/{:}/loss'.format(train_method))\n",
    "\n",
    "logdir='runs/{:}/loss'.format(train_method)\n",
    "writer = SummaryWriter(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_method==\"all_multi\":\n",
    "    #all the train data is multi question type\n",
    "    df=df_multi_train\n",
    "    train_texts=df_multi_train.loc[:,\"Question\"].values.tolist()\n",
    "    train_labels=df_multi_train.loc[:, \"Confirmation\":\"Complex\"].values.tolist()\n",
    "    val_texts=pd.concat([df_multi_test.loc[:,\"Question\"], df_single_test.loc[:,\"Question\"].sample(n=len(df_multi_test),replace=False, random_state=42)], ignore_index=True).values.tolist()\n",
    "    val_labels=pd.concat([df_multi_test.loc[:,\"Confirmation\":\"Complex\"], df_single_test.loc[:,\"Confirmation\":\"Complex\"].sample(n=len(df_multi_test),replace=False, random_state=42)], ignore_index=True).values.tolist()\n",
    "if train_method==\"half_multi_half_single\":\n",
    "    df=pd.concat([df_multi_train, df_single_train.sample(n=len(df_multi_train),replace=False, random_state=42)], ignore_index=True)\n",
    "    train_texts=df.loc[:,\"Question\"].values.tolist()\n",
    "    train_labels=df.loc[:,\"Confirmation\":\"Complex\"].values.tolist()\n",
    "    val_texts=pd.concat([df_multi_test.loc[:,\"Question\"], df_single_test.loc[:,\"Question\"].sample(n=len(df_multi_test),replace=False, random_state=42)], ignore_index=True).values.tolist()\n",
    "    val_labels=pd.concat([df_multi_test.loc[:,\"Confirmation\":\"Complex\"], df_single_test.loc[:,\"Confirmation\":\"Complex\"].sample(n=len(df_multi_test),replace=False, random_state=42)], ignore_index=True).values.tolist()\n",
    "if train_method==\"all_data\":\n",
    "    df=pd.concat([df_multi_train, df_single_train], ignore_index=True)\n",
    "    train_texts=df.loc[:,\"Question\"].values.tolist()\n",
    "    train_labels=df.loc[:,\"Confirmation\":\"Complex\"].values.tolist()\n",
    "    val_texts=pd.concat([df_multi_test.loc[:,\"Question\"], df_single_test.loc[:,\"Question\"].sample(n=len(df_multi_test),replace=False, random_state=42)], ignore_index=True).values.tolist()\n",
    "    val_labels=pd.concat([df_multi_test.loc[:,\"Confirmation\":\"Complex\"], df_single_test.loc[:,\"Confirmation\":\"Complex\"].sample(n=len(df_multi_test),replace=False, random_state=42)], ignore_index=True).values.tolist()\n",
    "if train_method==\"all_single\":\n",
    "    df=df_single_train\n",
    "    train_texts=df_single_train.loc[:,\"Question\"].values.tolist()\n",
    "    train_labels=df_single_train.loc[:, \"Confirmation\":\"Complex\"].values.tolist()\n",
    "    val_texts=pd.concat([df_multi_test.loc[:,\"Question\"], df_single_test.loc[:,\"Question\"].sample(n=len(df_multi_test),replace=False, random_state=42)], ignore_index=True).values.tolist()\n",
    "    val_labels=pd.concat([df_multi_test.loc[:,\"Confirmation\":\"Complex\"], df_single_test.loc[:,\"Confirmation\":\"Complex\"].sample(n=len(df_multi_test),replace=False, random_state=42)], ignore_index=True).values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "train_seq = torch.tensor(train_encodings['input_ids'])\n",
    "train_mask = torch.tensor(train_encodings['attention_mask'])\n",
    "train_y = torch.tensor(train_labels, dtype=torch.float)\n",
    "\n",
    "val_seq = torch.tensor(val_encodings['input_ids'])\n",
    "val_mask = torch.tensor(val_encodings['attention_mask'])\n",
    "val_y = torch.tensor(val_labels, dtype=torch.float)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoader\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=500\n",
    "early_stopping_patience = 30 \n",
    "best_loss = np.Inf\n",
    "early_stopping_counter = 0  \n",
    "lr=2e-6\n",
    "start_epoch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\ProjectFiles\\Python\\NLP\\FINAL\\Question_type\\model.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.label_weight = torch.tensor(label_weight)\n",
      "e:\\InstalledFile\\Anaconda\\envs\\NLP\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 44 train loss:0.066992,val loss:0.375491:   9%|â–‰         | 45/500 [26:45<4:30:37, 35.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 45 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from model import BERTMultiLabelBinaryClassification,BERTMultiLabelBinaryClassification_FactorLoss\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "positive_proportions = df[['Confirmation', 'Factoid', 'List', 'Causal', 'Hypothetical', 'Complex']].sum() / len(df[['Confirmation', 'Factoid', 'List', 'Causal', 'Hypothetical', 'Complex']])\n",
    "negative_proportions = 1 - positive_proportions\n",
    "label_weight=negative_proportions/positive_proportions\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = BERTMultiLabelBinaryClassification(num_labels=6,label_weight=label_weight)\n",
    "model = BERTMultiLabelBinaryClassification_FactorLoss(num_labels=6,label_weight=label_weight,gamma=2.5,mix_ratio=0.3)\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(load_model_name))\n",
    "optimizer = AdamW(model.parameters(), lr=lr,weight_decay=0.001)\n",
    "loss_fn = BCEWithLogitsLoss()\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=5, \n",
    "                                            num_training_steps=len(train_dataloader)*epochs)\n",
    "progress_bar = tqdm(range(start_epoch,epochs), desc='Training Progress')\n",
    "model=model.to(device)\n",
    "for epoch in progress_bar: \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "        loss = model(**inputs)\n",
    "\n",
    "        #loss = loss_fn(outputs, inputs['labels'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    total_loss=total_loss / len(train_dataloader)\n",
    "\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {'input_ids': batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels': batch[2]}\n",
    "            loss = model(**inputs)\n",
    "            #batch_loss = loss_fn(outputs, inputs['labels'])\n",
    "            val_loss += loss.item()\n",
    "    val_loss = val_loss / len(val_dataloader)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        early_stopping_counter = 0 \n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs.\")\n",
    "            break\n",
    "    writer.add_scalars(\"loss\",{\"train loss\":total_loss,\"val loss\":val_loss},epoch)\n",
    "    progress_bar.set_description(\"Epoch {:} train loss:{:.6f},val loss:{:.6f}\".format(epoch,total_loss,val_loss))\n",
    "model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.5953 Precision:0.8590 Recall:0.7846 F1 Score:0.8201 ROC AUC:0.9643\n",
      "Confirmation Accuracy:0.9415 Precision:0.9415 Recall:0.9415 F1 Score:0.9415 ROC AUC:0.9766\n",
      "Factoid Accuracy:0.7458 Precision:0.7458 Recall:0.7458 F1 Score:0.7458 ROC AUC:0.8349\n",
      "List Accuracy:0.9967 Precision:0.9967 Recall:0.9967 F1 Score:0.9967 ROC AUC:0.9993\n",
      "Causal Accuracy:0.9080 Precision:0.9080 Recall:0.9080 F1 Score:0.9080 ROC AUC:0.9661\n",
      "Hypothetical Accuracy:0.9967 Precision:0.9967 Recall:0.9967 F1 Score:0.9967 ROC AUC:0.9998\n",
      "Complex Accuracy:0.8796 Precision:0.8796 Recall:0.8796 F1 Score:0.8796 ROC AUC:0.9018\n",
      "Single-type qutions Accuracy:0.6522 Precision:0.7123 Recall:0.8361 F1 Score:0.7692 ROC AUC:0.9543\n",
      "Multi-type qutions Accuracy:0.5385 Precision:0.9635 Recall:0.7600 F1 Score:0.8497 ROC AUC:0.9822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.to(device)\n",
    "    for batch in val_dataloader:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1]\n",
    "        }\n",
    "        labels = batch[2]\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        logits =  torch.sigmoid(outputs).detach().cpu().numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "\n",
    "predictions = np.vstack(predictions) \n",
    "true_labels = np.vstack(true_labels) \n",
    "\n",
    "pred_labels=np.zeros_like(predictions)\n",
    "split=[0.5,0.5,0.5,0.5,0.5,0.5]\n",
    "for i in range(len(split)):\n",
    "    predictions[:,i]=predictions[:,i]/predictions[:,i].max()\n",
    "    pred_labels[:,i]=(predictions[:,i] > split[i]).astype(int)\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='micro')\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "roc_auc = roc_auc_score(true_labels, predictions, average='micro')\n",
    "\n",
    "writer.add_text(\"Evaluation\",\"Accuracy:{:.4f} Precision:{:.4f} Recall:{:.4f} F1 Score:{:.4f} ROC AUC:{:.4f}\".format(accuracy,precision,recall,f1,roc_auc))\n",
    "print(\"Accuracy:{:.4f} Precision:{:.4f} Recall:{:.4f} F1 Score:{:.4f} ROC AUC:{:.4f}\".format(accuracy,precision,recall,f1,roc_auc))\n",
    "\n",
    "list_name=['Confirmation','Factoid','List','Causal','Hypothetical','Complex']\n",
    "for i in range(6):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels[:,i], pred_labels[:,i], average='micro')\n",
    "    accuracy = accuracy_score(true_labels[:,i], pred_labels[:,i])\n",
    "    roc_auc = roc_auc_score(true_labels[:,i], predictions[:,i], average='micro')\n",
    "    writer.add_text(\"Evaluation\",\"{:} Accuracy:{:.4f} Precision:{:.4f} Recall:{:.4f} F1 Score:{:.4f} ROC AUC:{:.4f}\".format(list_name[i],accuracy,precision,recall,f1,roc_auc))\n",
    "    print(\"{:} Accuracy:{:.4f} Precision:{:.4f} Recall:{:.4f} F1 Score:{:.4f} ROC AUC:{:.4f}\".format(list_name[i],accuracy,precision,recall,f1,roc_auc))\n",
    "\n",
    "index = (true_labels.sum(axis=1) == 1)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels[index], pred_labels[index], average='micro')\n",
    "accuracy = accuracy_score(true_labels[index], pred_labels[index])\n",
    "roc_auc = roc_auc_score(true_labels[index], predictions[index], average='micro')\n",
    "\n",
    "writer.add_text(\"Evaluation\",\"Single-type qutions Accuracy:{:.4f} Precision:{:.4f} Recall:{:.4f} F1 Score:{:.4f} ROC AUC:{:.4f}\".format(accuracy,precision,recall,f1,roc_auc))\n",
    "print(\"Single-type qutions Accuracy:{:.4f} Precision:{:.4f} Recall:{:.4f} F1 Score:{:.4f} ROC AUC:{:.4f}\".format(accuracy,precision,recall,f1,roc_auc))\n",
    "\n",
    "index = (true_labels.sum(axis=1) > 1)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels[index], pred_labels[index], average='micro')\n",
    "accuracy = accuracy_score(true_labels[index], pred_labels[index])\n",
    "roc_auc = roc_auc_score(true_labels[index], predictions[index], average='micro')\n",
    "\n",
    "print(\"Multi-type qutions Accuracy:{:.4f} Precision:{:.4f} Recall:{:.4f} F1 Score:{:.4f} ROC AUC:{:.4f}\".format(accuracy,precision,recall,f1,roc_auc))\n",
    "writer.add_text(\"Evaluation\",\"Multi-type qutions Accuracy:{:.4f} Precision:{:.4f} Recall:{:.4f} F1 Score:{:.4f} ROC AUC:{:.4f}\".format(accuracy,precision,recall,f1,roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_state_dict_{:}.pth'.format(train_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sentence=\"Is Paris the capital of France?\"\n",
    "\n",
    "sentence_encodings = tokenizer(sentence, truncation=True, padding=True, max_length=128)\n",
    "sentence_seq = torch.tensor(sentence_encodings['input_ids'])\n",
    "sentence_mask = torch.tensor(sentence_encodings['attention_mask'])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model.cpu()\n",
    "    inputs = {\n",
    "            'input_ids':sentence_seq.unsqueeze(0),\n",
    "            'attention_mask':sentence_mask.unsqueeze(0)\n",
    "        }\n",
    "    outputs = model(**inputs)\n",
    "    logits =  torch.sigmoid(outputs).detach().cpu().numpy()\n",
    "    #logits = outputs.detach().cpu().numpy()\n",
    "pred_labels=(logits > 0.5).astype(int)\n",
    "print(pred_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
